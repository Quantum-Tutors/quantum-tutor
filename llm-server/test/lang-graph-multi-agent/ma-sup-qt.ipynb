{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    "    AIMessage\n",
    ")\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from pydantic import BaseModel\n",
    "from typing import Annotated, Sequence, TypedDict, Literal, List\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join('../config/','.env'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "conversation_states = ['Initial','Exploring','Probing','Concluding']\n",
    "members = ['conversation_state_tracker']\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "class conversationStateTrackerResponse(BaseModel):\n",
    "    content: Literal[*conversation_states]\n",
    "    \n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]\n",
    "    \n",
    "# Helper function to create a node for a given agent\n",
    "def agent_node(state, agent, name) -> AgentState:\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [ AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)],\"next\":\"supervisor\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversation_state_tracker(llm):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Analyze the messages:\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"Determine the current conversation state in Socratic learning Method to decide what to do next. \"\n",
    "                \"Consider factors such as the topic, depth of discussion, and user engagement. \"\n",
    "                \"Return one from this List [Initial,Exploring,Probing,Concluding]\"\n",
    "                \"Respond with only on of the possible states and explanation for each states are as follows:\"\n",
    "                \"    - Initial -> meaning that the user is at The beginning stage of the conversation.\"\n",
    "                \"    - Exploring -> meaning that the user is at an In-depth discussion and exploration of topics.\"\n",
    "                \"    - Probing -> meaning that the user is Asking deeper questions to uncover more information.\"\n",
    "                \"    - Concluding -> meaning that the user is at Wrapping up the conversation and reaching a conclusion.\"\n",
    "                \"Example for each state value:\"\n",
    "                \"    -   query: 'Hi, I'm new to Machine Learning, where should I start?' \"\n",
    "                \"        return: 'Initial'\"\n",
    "                \"    -   query: 'Can you explain the difference between supervised and unsupervised learning?' \"\n",
    "                \"        return: 'Exploring'\"\n",
    "                \"    -   query: 'What happens if we use a high learning rate in training?' \"\n",
    "                \"        return: 'Probing'\"\n",
    "                \"    -   query: 'Got it, thanks for your help with Machine Learning basics.' \"\n",
    "                \"        return: 'Concluding'\"\n",
    "                # \"Also finally once the state has been decided, return FINISH for the next variable\"\n",
    "            ),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "    return prompt | llm\n",
    "    # return prompt | llm.with_structured_output(conversationStateTrackerResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are helpful assistant, who can perform required task\"\n",
    "    \"Given a task you need to return the current state of the conversation\"\n",
    "    # \"You are the best Socratic tutor, guiding the user towards understanding their own errors or misconceptions or in learning a new concept.\"\n",
    "    # \"Your role:\"\n",
    "    # \"    Questioning: Ask probing questions to challenge the user's assumptions and encourage deeper thinking.\"\n",
    "    # \"    Clarification: Request clarification when the user's responses are unclear or contradictory.\"\n",
    "    # \"    Counter-arguments: Present counter-arguments to the user's claims to help them identify flaws in their reasoning.\"\n",
    "    # \"    Guidance: Provide hints or suggestions to nudge the user towards the correct understanding.\"\n",
    "    # \"    New Concepts: If learning new concepts, then list some related concepts to the given concept and ask the user whether he knows it or not. \"\n",
    "    # \"    Based on his existing knowledge, ask questions on the concpets he knows and converge on the new concept.\"\n",
    "    # \"Focus:\"\n",
    "    # \"    Concept understanding: Help the user grasp the underlying concepts and principles.\"\n",
    "    # \"    Error identification: Assist the user in recognizing and correcting their mistakes.\"\n",
    "    # \"    Critical thinking: Encourage the user to think critically and evaluate their own arguments.\"\n",
    "    # \"Example Questions: (Ask such questions with respect to the context the user has provided.)\"\n",
    "    #     \"Can you explain why you chose this approach?\"\n",
    "    #     \"What are the potential drawbacks of this solution?\"\n",
    "    #     \"How could you test your code to verify its correctness?\"\n",
    "    #     \"Can you think of a simpler or more efficient way to achieve the same result?\"\n",
    "    # \"Remember: Your primary goal is to facilitate learning, not to provide answers. \"\n",
    "    # \"By asking thought-provoking questions, you can help the user develop a deeper understanding of the topic and improve their problem-solving skills.\"\n",
    "    \"You have access to the following workers:\"\n",
    "    \"{members} used to retrieve the current state of the conversation.\"\n",
    "    \"When you need to use a worker respond with the worker to act next\"\n",
    "    \"Once you have received the state, respond with FINISH\"\n",
    ")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-groq-8b-8192-tool-use-preview\",\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        prompt\n",
    "        | llm.with_structured_output(routeResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_state_tracker_agent = create_conversation_state_tracker(llm)\n",
    "conversation_state_tracker_node = functools.partial(agent_node, agent=conversation_state_tracker_agent, name='conversation_state_tracker')\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"conversation_state_tracker\", conversation_state_tracker_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "\n",
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "    \n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "\n",
    "def router(state) -> Literal[*options]:\n",
    "    print('state', state)\n",
    "    if \"FINISH\" == state['next']:\n",
    "        return \"FINISH\"\n",
    "    else:\n",
    "        return state['next']\n",
    "\n",
    "# def router(supervisor_response: routeResponse) -> Literal[*options]:\n",
    "#     print(supervisor_response)\n",
    "#     return supervisor_response['next']\n",
    "\n",
    "workflow.add_conditional_edges(\"supervisor\", router, conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state {'messages': [HumanMessage(content='Hi, I wanna learn Datastructures')], 'next': 'conversation_state_tracker'}\n",
      "{'supervisor': {'next': 'conversation_state_tracker'}}\n",
      "----\n",
      "{'conversation_state_tracker': {'messages': [AIMessage(content='Based on the conversation, the current state is \"Initial\". The user is at the beginning stage of the conversation, expressing interest in learning Datastructures.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 283, 'total_tokens': 314, 'completion_time': 0.027876834, 'prompt_time': 0.038160607, 'queue_time': 0.0009543730000000014, 'total_time': 0.066037441}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='conversation_state_tracker', id='run-b225e944-f741-4bae-a379-78e931776148-0', usage_metadata={'input_tokens': 283, 'output_tokens': 31, 'total_tokens': 314})], 'next': 'supervisor'}}\n",
      "----\n",
      "state {'messages': [HumanMessage(content='Hi, I wanna learn Datastructures'), AIMessage(content='Based on the conversation, the current state is \"Initial\". The user is at the beginning stage of the conversation, expressing interest in learning Datastructures.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 283, 'total_tokens': 314, 'completion_time': 0.027876834, 'prompt_time': 0.038160607, 'queue_time': 0.0009543730000000014, 'total_time': 0.066037441}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='conversation_state_tracker', id='run-b225e944-f741-4bae-a379-78e931776148-0', usage_metadata={'input_tokens': 283, 'output_tokens': 31, 'total_tokens': 314})], 'next': 'conversation_state_tracker'}\n",
      "{'supervisor': {'next': 'conversation_state_tracker'}}\n",
      "----\n",
      "{'conversation_state_tracker': {'messages': [AIMessage(content='The current conversation state is \"Initial\". The user is at the beginning stage of the conversation, expressing interest in learning Datastructures.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 318, 'total_tokens': 345, 'completion_time': 0.024135857, 'prompt_time': 0.042614606, 'queue_time': 0.001021873999999999, 'total_time': 0.066750463}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='conversation_state_tracker', id='run-cdfb1111-f497-4813-a815-709c4f2aa5da-0', usage_metadata={'input_tokens': 318, 'output_tokens': 27, 'total_tokens': 345})], 'next': 'supervisor'}}\n",
      "----\n",
      "state {'messages': [HumanMessage(content='Hi, I wanna learn Datastructures'), AIMessage(content='Based on the conversation, the current state is \"Initial\". The user is at the beginning stage of the conversation, expressing interest in learning Datastructures.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 283, 'total_tokens': 314, 'completion_time': 0.027876834, 'prompt_time': 0.038160607, 'queue_time': 0.0009543730000000014, 'total_time': 0.066037441}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='conversation_state_tracker', id='run-b225e944-f741-4bae-a379-78e931776148-0', usage_metadata={'input_tokens': 283, 'output_tokens': 31, 'total_tokens': 314}), AIMessage(content='The current conversation state is \"Initial\". The user is at the beginning stage of the conversation, expressing interest in learning Datastructures.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 318, 'total_tokens': 345, 'completion_time': 0.024135857, 'prompt_time': 0.042614606, 'queue_time': 0.001021873999999999, 'total_time': 0.066750463}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='conversation_state_tracker', id='run-cdfb1111-f497-4813-a815-709c4f2aa5da-0', usage_metadata={'input_tokens': 318, 'output_tokens': 27, 'total_tokens': 345})], 'next': 'conversation_state_tracker'}\n",
      "{'supervisor': {'next': 'conversation_state_tracker'}}\n",
      "----\n",
      "{'conversation_state_tracker': {'messages': [AIMessage(content='The current conversation state is \"Initial\". The user is at the beginning stage of the conversation, expressing interest in learning Datastructures.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 349, 'total_tokens': 376, 'completion_time': 0.024181586, 'prompt_time': 0.047152731, 'queue_time': 0.001096105, 'total_time': 0.071334317}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='conversation_state_tracker', id='run-916ffce8-225d-4e74-9780-5eebd4b2a110-0', usage_metadata={'input_tokens': 349, 'output_tokens': 27, 'total_tokens': 376})], 'next': 'supervisor'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Hi, I wanna learn Datastructures\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
