{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    "    AIMessage\n",
    ")\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from pydantic import BaseModel\n",
    "from typing import Annotated, Sequence, TypedDict, Literal, List\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join('../config/','.env'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINISH,convo_state_tracker,generate_assessments'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_states = ['Initial','Exploring','Probing','Concluding']\n",
    "members = ['convo_state_tracker', 'generate_assessments']\n",
    "options = [\"FINISH\"] + members\n",
    "','.join(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"llama3-groq-8b-8192-tool-use-preview\",\n",
    "#     # model=\"llama-3.1-8b-instant\",\n",
    "#     temperature=0.0,\n",
    "#     max_retries=2,\n",
    "# )\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model='llama3-groq-tool-use:latest',\n",
    "#     # model='llama3.1',\n",
    "#     temperature=0.0,\n",
    "# )\n",
    "\n",
    "# llm = AzureChatOpenAI(\n",
    "#             api_key='6060de1a99394ebda50e0ecb1258883b',\n",
    "#             api_version='2024-05-01-preview',\n",
    "#             azure_endpoint='https://openai-pragateesh.openai.azure.com/',\n",
    "#             deployment_name='gpt-4'\n",
    "#         )   \n",
    "\n",
    "llm = Gemini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_supervisor_agent(llm, tools):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are helpful assistant, who can perform required task\"\n",
    "                \"You are the best Socratic tutor, guiding the user towards understanding their own errors or misconceptions or in learning a new concept.\"\n",
    "                \"Your role:\"\n",
    "                \"    Questioning: Ask probing questions to challenge the user's assumptions and encourage deeper thinking.\"\n",
    "                \"    Clarification: Request clarification when the user's responses are unclear or contradictory.\"\n",
    "                \"    Counter-arguments: Present counter-arguments to the user's claims to help them identify flaws in their reasoning.\"\n",
    "                \"    Guidance: Provide hints or suggestions to nudge the user towards the correct understanding.\"\n",
    "                \"    New Concepts: If learning new concepts, then list some related concepts to the given concept and ask the user whether he knows it or not. \"\n",
    "                \"    Based on his existing knowledge, ask questions on the concpets he knows and converge on the new concept.\"\n",
    "                \"First of all when you get a message, follow these step:\"\n",
    "                \"   1. Get the state of the current conversation using one of the worker\"\n",
    "                \"   2. Once you got the state if it's initial generate an assessment for the user with 3-5 questions regarding the topic provide by user, using one of the worker.\"\n",
    "                \"   3. Evaluate the user based on his answers to the assessment generated.\"\n",
    "                \"   4. Once you have evaluated his performance, then start to ask questions using one of the workers by passing the state and chat history to one of the worker.\"\n",
    "                \"   5. Repeat the same process, until the user is satisfied in learning a topic or explicitly asked to change to new topic by the user.\"\n",
    "                \"Focus:\"\n",
    "                \"    Concept understanding: Help the user grasp the underlying concepts and principles.\"\n",
    "                \"    Error identification: Assist the user in recognizing and correcting their mistakes.\"\n",
    "                \"    Critical thinking: Encourage the user to think critically and evaluate their own arguments.\"\n",
    "                \"Remember: Your primary goal is to facilitate learning, not to provide answers. \"\n",
    "                \"By asking thought-provoking questions, you can help the user develop a deeper understanding of the topic and improve their problem-solving skills.\"\n",
    "\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = (\n",
    "#     \"You are helpful assistant, who can perform required task\"\n",
    "#     \"You are the best Socratic tutor, guiding the user towards understanding their own errors or misconceptions or in learning a new concept.\"\n",
    "#     \"Your role:\"\n",
    "#     \"    Questioning: Ask probing questions to challenge the user's assumptions and encourage deeper thinking.\"\n",
    "#     \"    Clarification: Request clarification when the user's responses are unclear or contradictory.\"\n",
    "#     \"    Counter-arguments: Present counter-arguments to the user's claims to help them identify flaws in their reasoning.\"\n",
    "#     \"    Guidance: Provide hints or suggestions to nudge the user towards the correct understanding.\"\n",
    "#     \"    New Concepts: If learning new concepts, then list some related concepts to the given concept and ask the user whether he knows it or not. \"\n",
    "#     \"    Based on his existing knowledge, ask questions on the concpets he knows and converge on the new concept.\"\n",
    "#     \"First of all when you get a message, follow these step:\"\n",
    "#     \"   1. Get the state of the current conversation using one of the worker\"\n",
    "#     \"   2. Once you got the state if it's initial generate an assessment for the user with 3-5 questions regarding the topic provide by user, using one of the worker.\"\n",
    "#     \"   3. Evaluate the user based on his answers to the assessment generated.\"\n",
    "#     \"   4. Once you have evaluated his performance, then start to ask questions using one of the workers by passing the state and chat history to one of the worker.\"\n",
    "#     \"   5. Repeat the same process, until the user is satisfied in learning a topic or explicitly asked to change to new topic by the user.\"\n",
    "#     \"Focus:\"\n",
    "#     \"    Concept understanding: Help the user grasp the underlying concepts and principles.\"\n",
    "#     \"    Error identification: Assist the user in recognizing and correcting their mistakes.\"\n",
    "#     \"    Critical thinking: Encourage the user to think critically and evaluate their own arguments.\"\n",
    "#     \"Remember: Your primary goal is to facilitate learning, not to provide answers. \"\n",
    "#     \"By asking thought-provoking questions, you can help the user develop a deeper understanding of the topic and improve their problem-solving skills.\"\n",
    "#     \"You have access to the following workers:\"\n",
    "#     \"{options}\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool #convo_state_tracker\n",
    "def convo_state_tracker(messages: AgentState):\n",
    "    \"\"\"A tool, that can analyze the current conversation and return from one of the values: ['Initial','Exploring','Probing','Concluding']\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "        system,\n",
    "        Analyze the messages:\n",
    "        {messages}\n",
    "        Determine the current conversation state in Socratic learning Method to decide what to do next. \n",
    "        Consider factors such as the topic, depth of discussion, and user engagement. \n",
    "        Return one from this List [Initial,Exploring,Probing,Concluding]\n",
    "        Respond with only on of the possible states and explanation for each states are as follows:\n",
    "            - Initial -> meaning that the user is at The beginning stage of the conversation.\n",
    "            - Exploring -> meaning that the user is at an In-depth discussion and exploration of topics.\n",
    "            - Probing -> meaning that the user is Asking deeper questions to uncover more information.\n",
    "            - Concluding -> meaning that the user is at Wrapping up the conversation and reaching a conclusion.\n",
    "        Example for each state value:\n",
    "            - query: 'Hi, I'm new to Machine Learning, where should I start?' \n",
    "            return: 'Initial'\n",
    "            - query: 'Can you explain the difference between supervised and unsupervised learning?' \n",
    "            return: 'Exploring'\n",
    "            - query: 'What happens if we use a high learning rate in training?' \n",
    "            return: 'Probing'\n",
    "            - query: 'Got it, thanks for your help with Machine Learning basics.' \n",
    "            return: 'Concluding'\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    return (\n",
    "        result + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool #generate_assessment\n",
    "def generate_assessments(messages: AgentState):\n",
    "    \"\"\"A tool that can generate 5 questions that is used to evaluate the user's understanding level of a particular topic\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "        system,\n",
    "        Analyze the messages:\n",
    "        {messages}\n",
    "        Task: \n",
    "            Analyze the provided message history and generate 5 insightful questions that can assess the user's\n",
    "            understanding of the topic. The questions should be tailored to the specific content discussed in the \n",
    "            messages, incorporating relevant topic data structures where applicable. The question must be simple\n",
    "            enough to be answered in a single reply for all the questions in the next query.\n",
    "\n",
    "        Guidelines:\n",
    "         - Relevance: Ensure the questions directly relate to the key points or themes addressed in the message history.\n",
    "         - Clarity: Frame the questions in a clear and concise manner, avoiding ambiguity or vagueness.\n",
    "         - Variety: Strive for a mix of question types (e.g., open-ended, multiple-choice, short answer) to assess different aspects of understanding.\n",
    "         - Difficulty: Consider the user's likely level of knowledge and adjust the difficulty of the questions accordingly.\n",
    "         - Data Structures: When appropriate, incorporate topic-specific data structures (e.g., graphs, trees, arrays) into the questions to assess the user's ability to apply their knowledge to real-world scenarios.\n",
    "    \n",
    "    Note: The specific data structures used in the questions will depend on the topic being discussed in the message history.\n",
    "    For example, if the topic is graph algorithms, questions might involve concepts like adjacency matrices, adjacency lists, or depth-first search.\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    return (\n",
    "        result + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m convo_state_tracker_agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_agent\u001b[49m(\n\u001b[1;32m      2\u001b[0m     llm,\n\u001b[1;32m      3\u001b[0m     [convo_state_tracker],\n\u001b[1;32m      4\u001b[0m     system_message\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA tool, that can analyze the current conversation and return from one of the values: [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExploring\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcluding\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m convo_state_tracker_node \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(agent_node, agent\u001b[38;5;241m=\u001b[39mconvo_state_tracker_agent, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvo_state_tracker_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m generate_assessments_agent \u001b[38;5;241m=\u001b[39m create_agent(\n\u001b[1;32m      9\u001b[0m     llm,\n\u001b[1;32m     10\u001b[0m     [generate_assessments],\n\u001b[1;32m     11\u001b[0m     system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAny charts you display will be visible by the user.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_agent' is not defined"
     ]
    }
   ],
   "source": [
    "convo_state_tracker_agent = create_agent(\n",
    "    llm,\n",
    "    [convo_state_tracker],\n",
    "    system_message= \"A tool, that can analyze the current conversation and return from one of the values: ['Initial','Exploring','Probing','Concluding']\",\n",
    ")\n",
    "convo_state_tracker_node = functools.partial(agent_node, agent=convo_state_tracker_agent, name=\"convo_state_tracker_agent\")\n",
    "\n",
    "generate_assessments_agent = create_agent(\n",
    "    llm,\n",
    "    [generate_assessments],\n",
    "    system_message=\"Any charts you display will be visible by the user.\",\n",
    ")\n",
    "generate_assessments_node = functools.partial(agent_node, agent=generate_assessments_agent, name=\"generate_assessments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [convo_state_tracker, generate_assessments]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    # This is the router  \n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        # The previous agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return \"__end__\"\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"convo_state_tracker\", convo_state_tracker_node)\n",
    "workflow.add_node(\"generate_assessments\", generate_assessments_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "conditional_map = {node:node for node in members}\n",
    "conditional_map[\"call_tool\"] = \"call_tool\"\n",
    "conditional_map[\"__end__\"] = END\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"convo_state_tracker\",\n",
    "    router,\n",
    "    {'continue':'generate_assessments','call_tool': 'call_tool', '__end__': END}\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_assessments\",\n",
    "    router,\n",
    "    {'continue':END,'call_tool': 'call_tool', '__end__': END}\n",
    "\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    lambda x: x[\"sender\"],\n",
    "    {node:node for node in members}\n",
    ")\n",
    "\n",
    "workflow.add_edge(START, \"convo_state_tracker\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "# except Exception:\n",
    "#     # This requires some extra dependencies and is optional\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'convo_state_tracker': {'messages': [AIMessage(content='Sure, I can help with that. What specific aspect of Datastructures are you interested in?', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 980, 'total_tokens': 1000, 'completion_time': 0.017711488, 'prompt_time': 0.130411703, 'queue_time': 0.0014547659999999962, 'total_time': 0.148123191}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='convo_state_tracker_agent', id='run-9970263d-25c6-4cff-a3b1-161056b20106-0', usage_metadata={'input_tokens': 980, 'output_tokens': 20, 'total_tokens': 1000})], 'sender': 'convo_state_tracker_agent'}}\n",
      "----\n",
      "{'generate_assessments': {'messages': [AIMessage(content=\"I'm interested in learning about algorithms and their implementations.\", response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 980, 'total_tokens': 992, 'completion_time': 0.010251569, 'prompt_time': 0.129510672, 'queue_time': 0.0012374300000000116, 'total_time': 0.139762241}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, name='generate_assessments', id='run-44cf8454-827d-4271-9a75-b106654e7d09-0', usage_metadata={'input_tokens': 980, 'output_tokens': 12, 'total_tokens': 992})], 'sender': 'generate_assessments'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Hi, I wanna learn Datastructures\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")\n",
    "        res.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'convo_state_tracker': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2yjh', 'function': {'arguments': '{\"messages\": [{\"content\": \"Hi, I wanna learn Datastructures\", \"type\": \"user\"}]}', 'name': 'convo_state_tracker'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 986, 'total_tokens': 1031, 'completion_time': 0.040843041, 'prompt_time': 0.130306235, 'queue_time': 0.001110252000000006, 'total_time': 0.171149276}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'tool_calls', 'logprobs': None}, name='convo_state_tracker_agent', id='run-c90fa38a-adb6-43b8-a595-a1157a807596-0', tool_calls=[{'name': 'convo_state_tracker', 'args': {'messages': [{'content': 'Hi, I wanna learn Datastructures', 'type': 'user'}]}, 'id': 'call_2yjh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 986, 'output_tokens': 45, 'total_tokens': 1031})], 'sender': 'convo_state_tracker_agent'}}\n",
      "----\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'convo_state_tracker_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCount the words, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHi, I wanna learn Datastructures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1287\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1717\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(futs, step, timeout_exc_cls)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1716\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1722\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langgraph/pregel/executor.py:59\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:26\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     24\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2878\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2877\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2878\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langgraph/utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m    101\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 102\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langgraph/graph/graph.py:89\u001b[0m, in \u001b[0;36mBranch._route\u001b[0;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[1;32m     87\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m     88\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minvoke(value, config)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/challenges/google-genai-xchange/quantum-tutor/.venv/lib/python3.12/site-packages/langgraph/graph/graph.py:116\u001b[0m, in \u001b[0;36mBranch._finish\u001b[0;34m(self, writer, input, result)\u001b[0m\n\u001b[1;32m    114\u001b[0m     result \u001b[38;5;241m=\u001b[39m [result]\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mends:\n\u001b[0;32m--> 116\u001b[0m     destinations \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, Send) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     destinations \u001b[38;5;241m=\u001b[39m result\n",
      "\u001b[0;31mKeyError\u001b[0m: 'convo_state_tracker_agent'"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Count the words, 'Hi, I wanna learn Datastructures'\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
