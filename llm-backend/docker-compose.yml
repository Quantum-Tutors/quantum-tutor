services:
  server:
    image: server:latest
    command: sh -c "python -m server.app"
    env_file:
      - ./server/config/.env
    network_mode: "host"
    volumes:
      - ./server:/server
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./server/Dockerfile
    healthcheck:
      test: wget --no-verbose --tries=1 http://localhost:5000/ || exit 1  # Use localhost
      interval: 30s
      retries: 5
      start_period: 15s
      timeout: 10s

  control_plane:
    image: control_plane:latest
    command: sh -c "python -m core_systems.main"
    network_mode: "host"
    volumes:
      - ./llm_deploy/core_systems:/core_systems
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./llm_deploy/core_systems/Dockerfile
    healthcheck:
      test: wget --no-verbose --tries=1 http://localhost:8000/ || exit 1  # Use localhost
      interval: 30s
      retries: 5
      start_period: 5s
      timeout: 10s
      
  concierge_workflow:
    image: concierge_workflow:latest
    command: sh -c "python -m workflows.concierge"
    env_file:
      - ./llm_deploy/workflows/.env
    network_mode: "host"
    volumes:
      - ./llm_deploy/workflows:/workflows
      - ~/.config/gcloud:/root/.config/gcloud
    platform: linux/amd64
    # depends_on:
    #   control_plane:
    #     condition: service_healthy
    build:
      context: .
      dockerfile: ./llm_deploy/workflows/Dockerfile
    healthcheck:
      test: wget --no-verbose --tries=1 http://localhost:8002/ || exit 1  # Use localhost
      interval: 30s
      retries: 5
      start_period: 20s
      timeout: 10s
